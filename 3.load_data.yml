Description: Creates Data Lake Imovel

#Todos os recursos da Aws
Resources:
  KinesisStream:
    Type: AWS::Kinesis::Stream
    Properties:
      Name: kinesis-stream
      RetentionPeriodHours: 24 # Dados em background por 24h
      ShardCount: 1
      StreamEncryption:
        EncryptionType: KMS
        KeyId: alias/aws/kinesis

  KinesisFirehoseS3Destination:
    Type: AWS::KinesisFirehose::DeliveryStream
    Properties:
      DeliveryStreamName: kinesis-firehose-delivery-stream-zapimovel
      DeliveryStreamType: DirectPut
      ExtendedS3DestinationConfiguration:
        BucketARN: !ImportValue data-lake-DataLakeImovelRawBucketArn
        BufferingHints:
          IntervalInSeconds: 60 # Tempo que o Kinesis vai esperar para jogar os dados no s3
          SizeInMBs: 1
        CompressionFormat: GZIP # Formato para salvar o arquivo
        ErrorOutputPrefix: bad_record_
        RoleARN: !GetAtt KinesisRole.Arn
        Prefix: "zapimoveis/year=!{timestamp:yyyy}/month=!{timestamp:MM}/day=!{timestamp:dd}/" #Nome do diretório que ele vai criar
#Não foi usado
  KinesisFirehoseS3DestinationNetImovel:
    Type: AWS::KinesisFirehose::DeliveryStream
    Properties:
      DeliveryStreamName: kinesis-firehose-delivery-stream-netimovel
      DeliveryStreamType: DirectPut
      ExtendedS3DestinationConfiguration:
        BucketARN: !ImportValue data-lake-DataLakeImovelRawBucketArn
        BufferingHints:
          IntervalInSeconds: 60 # Tempo que o Kinesis vai esperar para jogar os dados no s3
          SizeInMBs: 1
        CompressionFormat: GZIP # Formato para salvar o arquivo
        ErrorOutputPrefix: bad_record_
        RoleARN: !GetAtt KinesisRole.Arn
        Prefix: "netimoveis/year=!{timestamp:yyyy}/month=!{timestamp:MM}/day=!{timestamp:dd}/"

  KinesisLogGroup: # Grupo de log
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: kinesis-firehose-delivery-stream-log-group
      RetentionInDays: 1

  KinesisLogStream:
    Type: AWS::Logs::LogStream
    Properties:
      LogGroupName: !Ref KinesisLogGroup
      LogStreamName: kinesis-firehose-delivery-stream-log-stream

  KinesisRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: firehose.amazonaws.com
            Action:
              - sts:AssumeRole
      Description: Role to allow Kinesis to save data to S3
      ManagedPolicyArns:
        - !Ref KinesisPolicy
      Path: /
      RoleName: role-kinesis

  KinesisPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      Description: Policy to allow kinesis to access S3
      Path: /
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action:
              - s3:AbortMultipartUpload
              - s3:GetBucketLocation
              - s3:GetObject
              - s3:ListBucket
              - s3:ListBucketMultipartUploads
              - s3:PutObject
            Resource:
              - !ImportValue data-lake-DataLakeImovelRawBucketArn
              - !Join ["/", [!ImportValue data-lake-DataLakeImovelRawBucketArn, "*"]]

  RawZapImoveisCrawler:
    Type: AWS::Glue::Crawler
    Properties:
      Configuration: "{\"Version\":1.0,\"CrawlerOutput\":{\"Partitions\":{\"AddOrUpdateBehavior\":\"InheritFromTable\"}}}"
      DatabaseName: !ImportValue 'DataLakeImovelRawDatabase'
      Description: Raw Imovel Crawler
      Name: raw-mvp-zapimoveis-crawler
      Role: !ImportValue 'IamRoleDataLakeImovelGlue'
      Schedule:
        ScheduleExpression: 'cron(0 0 1 * ? *)'
      SchemaChangePolicy:
        DeleteBehavior: DEPRECATE_IN_DATABASE
        UpdateBehavior: UPDATE_IN_DATABASE
      Targets:
        S3Targets:
          - Path: !Join ['/', ['s3:/', !ImportValue data-lake-DataLakeImovelRawBucketName, 'zapimoveis']]

  RawNetImoveisCrawler:
    Type: AWS::Glue::Crawler
    Properties:
      Configuration: "{\"Version\":1.0,\"CrawlerOutput\":{\"Partitions\":{\"AddOrUpdateBehavior\":\"InheritFromTable\"}}}"
      DatabaseName: !ImportValue 'DataLakeImovelRawDatabase'
      Description: Raw Imovel Crawler
      Name: raw-mvp-netimovel-crawler
      Role: !ImportValue 'IamRoleDataLakeImovelGlue'
      Schedule:
        ScheduleExpression: 'cron(0 0 1 * ? *)'
      SchemaChangePolicy:
        DeleteBehavior: DEPRECATE_IN_DATABASE
        UpdateBehavior: UPDATE_IN_DATABASE
      Targets:
        S3Targets:
          - Path: !Join ['/', ['s3:/', !ImportValue data-lake-DataLakeImovelRawBucketName, 'netimoveis', 'public', 'netimoveis']]
        
  ProcessedZapImoveisCrawler:
    Type: AWS::Glue::Crawler
    Properties:
      Configuration: "{\"Version\":1.0,\"CrawlerOutput\":{\"Partitions\":{\"AddOrUpdateBehavior\":\"InheritFromTable\"}}}"
      DatabaseName: !ImportValue 'DataLakeImovelProcessedDatabase'
      Description: Processed Imovel Crawler
      Name: processed-mvp-zapimoveis-crawler
      Role: !ImportValue IamRoleDataLakeImovelGlue
      Schedule:
        ScheduleExpression: 'cron(0 0 1 * ? *)'
      SchemaChangePolicy:
        DeleteBehavior: DEPRECATE_IN_DATABASE
        UpdateBehavior: UPDATE_IN_DATABASE
      Targets:
        S3Targets:
          - Path: !Join ['/', ['s3:/', !ImportValue data-lake-DataLakeImovelProcessedBucketName, 'zapimoveis']]

  CuratedZapImoveisCrawler:
    Type: AWS::Glue::Crawler
    Properties:
      Configuration: "{\"Version\":1.0,\"CrawlerOutput\":{\"Partitions\":{\"AddOrUpdateBehavior\":\"InheritFromTable\"}}}"
      DatabaseName: !ImportValue 'DataLakeImovelProcessedDatabase'
      Description: Curated Imovel Crawler
      Name: curated-mvp-zapimoveis-crawler
      Role: !ImportValue 'IamRoleDataLakeImovelGlue'
      Schedule:
        ScheduleExpression: 'cron(0 0 1 * ? *)'
      SchemaChangePolicy:
        DeleteBehavior: DEPRECATE_IN_DATABASE
        UpdateBehavior: UPDATE_IN_DATABASE
      Targets: # Dependencias !ImportValue ( importar de outro recurso )
        S3Targets:
          - Path: !Join ['/', ['s3:/', !ImportValue data-lake-DataLakeImovelCuratedBucketName, 'zapimoveis']]

#Job que executa o script que está no s3 convert_to_parquet.py
  ZapImoveisRawGlueJob:
    Type: AWS::Glue::Job
    Properties:       
      Command:
        Name: glueetl 
        ScriptLocation: !Join ['/', ['s3:/', !ImportValue data-lake-GlueJobScriptsBucket, 'root', 'convert_to_parquet.py']]         
      Description: 'Converter arquivos da camada raw (json) para a camada processed (parquet)'      
      Name: 'job-convert-json-to-parquet'
      Role: !ImportValue 'IamRoleDataLakeImovelGlue'
